
---
lowercaseOutputName: true
rules:
  - pattern: metrics<name=(\S+)/(\S+)\.driver\.(\S+)\.StreamingMetrics\.streaming\.(\S+)><>Value
    name: spark_streaming_driver_$4
    labels:
      app_namespace: "$1"
      app_name: "$2"
  - pattern: metrics<name=(\S+)/(\S+)\.driver\.spark\.streaming\.(\S+)\.(\S+)><>Value
    name: spark_structured_streaming_driver_$4
    labels:
      app_namespace: "$1"
      app_name: "$2"
      query_name: "$3"
  - pattern: metrics<name=(\S+)/(\S+)\.(\S+)\.executor\.(\S+)><>Value
    name: spark_executor_$4
    type: GAUGE
    labels:
      app_namespace: "$1"
      app_name: "$2"
      executor_id: "$3"
  - pattern: metrics<name=(\S+)/(\S+)\.driver\.(BlockManager|DAGScheduler|jvm)\.(\S+)><>Value
    name: spark_driver_$3_$4
    type: GAUGE
    labels:
      app_namespace: "$1"
      app_name: "$2"
  - pattern: metrics<name=(\S+)/(\S+)\.driver\.DAGScheduler\.(.*)><>Count
    name: spark_driver_DAGScheduler_$3_count
    type: COUNTER
    labels:
      app_namespace: "$1"
      app_name: "$2"
  - pattern: metrics<name=(\S+)/(\S+)\.driver\.HiveExternalCatalog\.(.*)><>Count
    name: spark_driver_HiveExternalCatalog_$3_count
    type: COUNTER
    labels:
      app_namespace: "$1"
      app_name: "$2"
  - pattern: metrics<name=(\S+)/(\S+)\.driver\.CodeGenerator\.(.*)><>Count
    name: spark_driver_CodeGenerator_$3_count
    type: COUNTER
    labels:
      app_namespace: "$1"
      app_name: "$2"
  - pattern: metrics<name=(\S+)/(\S+)\.driver\.LiveListenerBus\.(.*)><>Count
    name: spark_driver_LiveListenerBus_$3_count
    type: COUNTER
    labels:
      app_namespace: "$1"
      app_name: "$2"
  - pattern: metrics<name=(\S+)/(\S+)\.driver\.LiveListenerBus\.(.*)><>Value
    name: spark_driver_LiveListenerBus_$3
    type: GAUGE
    labels:
      app_namespace: "$1"
      app_name: "$2"
  - pattern: metrics<name=(\S+)/(\S+)\.(.*)\.executor\.(.*)><>Count
    name: spark_executor_$4_count
    type: COUNTER
    labels:
      app_namespace: "$1"
      app_name: "$2"
      executor_id: "$3"
  - pattern: metrics<name=(\S+)/(\S+)\.([0-9]+)\.(jvm|NettyBlockTransfer)\.(.*)><>Value
    name: spark_executor_$4_$5
    type: GAUGE
    labels:
      app_namespace: "$1"
      app_name: "$2"
      executor_id: "$3"
  - pattern: metrics<name=(\S+)/(\S+)\.([0-9]+)\.HiveExternalCatalog\.(.*)><>Count
    name: spark_executor_HiveExternalCatalog_$4_count
    type: COUNTER
    labels:
      app_namespace: "$1"
      app_name: "$2"
      executor_id: "$3"
  - pattern: metrics<name=(\S+)/(\S+)\.([0-9]+)\.CodeGenerator\.(.*)><>Count
    name: spark_executor_CodeGenerator_$4_count
    type: COUNTER
    labels:
      app_namespace: "$1"
      app_name: "$2"
      executor_id: "$3"
##   kafka.consumer:type=consumer-fetch-manager-metrics,client-id="{client-id}",topic="{topic}"
#  - pattern: kafka.consumer<type=(.+), client-id=(.+), topic=(.+)><>Value
#    name: kafka_$1
#    labels:
#      type: "$1"
#      client-id: "$2"
#      topic: "$3"
##   kafka.consumer:type=consumer-fetch-manager-metrics,client-id="{client-id}"
##   kafka.consumer:type=consumer-coordinator-metrics,client-id=([-.\w]+)
##   kafka.consumer:type=consumer-fetch-manager-metrics,client-id=([-.w]+)
#  - pattern: kafka.consumer<type=(.+), client-id=(.+)><>Value
#    name: kafka_$1
#    labels:
#      type: "$1"
#      client-id: "$2"
##  kafka.consumer:type=consumer-fetch-manager-metrics,partition="{partition}",topic="{topic}",client-id="{client-id}"
#  - pattern: kafka.consumer<type=(.+), partition=(.+), topic=(.+) client-id=(.+)><>Value
#    name: kafka_$1
#    labels:
#      type: "$1"
#      partition: "$2"
#      topic: "$3"
#      client-id: "$4"
## kafka_consumer_fetch_manager_metrics_bytes_consumed_total{client_id="some_client-0",topic="some_topic",} 62818.0
## kafka_consumer_fetch_manager_metrics_records_consumed_total{client_id="some_client-0",topic="some_topic",} 137.0
#  - pattern: kafka.consumer<type=(.+), client-id=(.+), topic=(.+)><>(bytes-consumed-total|records-consumed-total)
#    name: kafka_$1
#    type: COUNTER
#    labels:
#      type: "$1"
#      client-id: "$2"
#      topic: "$3"
## kafka_consumer_fetch_manager_metrics_records_lag_max{client_id="some_client-0",} 0.0
#  - pattern: kafka.consumer<type=(.+), client-id=(.+)><>(records-lag-max)
#    name: kafka_$1_$3
#    labels:
#      client-id: "$2"
## Wildcard matchers for everything kafka related we have not caught yet
#  - pattern: kafka.(\w+)<type=(.+), <client-id=(.+)><>Value
#    name: kafka_$1_$2
#    type: GAUGE
#    labels:
#      type: "$2"
#      client-id: "$3"
## Wildcard matchers for everything kafka related we have not caught yet + percentiles
#  - pattern: kafka.(\w+)<type=(.+), (.+)=(.*)><>(\d+)thPercentile
#    name: kafka_$1_$2
#    type: GAUGE
#    labels:
#      "$2": "$2"
#      quantile: "0.$5"
## Wildcard matchers for everything kafka related we have not caught yet
#  - pattern: kafka.(\w+)<type=(.+)><>Value
#    name: kafka_$1
#    type: GAUGE
#    labels:
#      type: "$2"
#   One to rule them all
  - pattern: "kafka"
  - pattern: "metrics<name=master\\.(.*)><>Value"
    name: spark_master_$1
  - pattern: "metrics<name=worker\\.(.*)><>Value"
    name: spark_worker_$1
  - pattern: "metrics<name=(.*)\\.driver\\.(DAGScheduler|BlockManager|jvm)\\.(.*)><>Value"
    name: spark_driver_$2_$3
    type: GAUGE
    labels:
      app_id: "$1"
  - pattern: "metrics<name=(.*)\\.driver\\.DAGScheduler\\.(.*)><>Count"
    name: spark_driver_DAGScheduler_$2_count
    type: COUNTER
    labels:
      app_id: "$1"
  - pattern: "metrics<name=(.*)\\.driver\\.HiveExternalCatalog\\.(.*)><>Count"
    name: spark_driver_HiveExternalCatalog_$2_total
    type: COUNTER
    labels:
      app_id: "$1"
  - pattern: "metrics<name=(.*)\\.driver\\.CodeGenerator\\.(.*)><>Count"
    name: spark_driver_CodeGenerator_$2_count
    type: COUNTER
    labels:
      app_id: "$1"
  - pattern: "metrics<name=(.*)\\.driver\\.LiveListenerBus\\.(.*)><>Count"
    name: spark_driver_LiveListenerBus_$2_count
    type: COUNTER
    labels:
      app_id: "$1"
  - pattern: "metrics<name=(.*)\\.driver\\.LiveListenerBus\\.(.*)><>Value"
    name: spark_driver_LiveListenerBus_$2
    type: GAUGE
    labels:
      app_id: "$1"
  - pattern: "metrics<name=(.*)\\.driver\\.(.*)\\.StreamingMetrics\\.streaming\\.(.*)><>Value"
    name: spark_driver_streaming_$3
    labels:
      app_id: "$1"
      app_name: "$2"
  - pattern: "metrics<name=(.*)\\.driver\\.spark\\.streaming\\.(.*)\\.(.*)><>Value"
    name: spark_driver_structured_streaming_$3
    labels:
      app_id: "$1"
      query_name: "$2"
  - pattern: "metrics<name=(.*)\\.(.*)\\.executor\\.(.*)><>Value"
    name: spark_executor_$3
    type: GAUGE
    labels:
      app_id: "$1"
      executor_id: "$2"
  - pattern: "metrics<name=(.*)\\.(.*)\\.executor\\.(.*)><>Count"
    name: spark_executor_$3_total
    type: COUNTER
    labels:
      app_id: "$1"
      executor_id: "$2"
  - pattern: "metrics<name=(.*)\\.([0-9]+)\\.(jvm|NettyBlockTransfer)\\.(.*)><>Value"
    name: spark_executor_$3_$4
    type: GAUGE
    labels:
      app_id: "$1"
      executor_id: "$2"
  - pattern: "metrics<name=(.*)\\.([0-9]+)\\.HiveExternalCatalog\\.(.*)><>Count"
    name: spark_executor_HiveExternalCatalog_$3_count
    type: COUNTER
    labels:
      app_id: "$1"
      executor_id: "$2"
  - pattern: "metrics<name=(.*)\\.([0-9]+)\\.CodeGenerator\\.(.*)><>Count"
    name: spark_executor_CodeGenerator_$3_count
    type: COUNTER
    labels:
      app_id: "$1"
      executor_id: "$2"